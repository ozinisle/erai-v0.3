{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Challenge\n",
    "\n",
    "Commodity stock corresponding to a particular month expires at a particular date on the same month or the very next month For example, Crude Oil Stock for a particular month expires on 18th of the next calendar month or the last working day before the 18th of the next calendar day if it falls on a stock market holiday\n",
    "\n",
    "Hence a CrudeOil Stock of March shall expire on 18th of April for a given year or on a working day prior to 18th if 18th is a holiay\n",
    "\n",
    "Typically one can buy a particular month's stock way a head of time. Say you can buy a Crude oil stock corresponding to the month of june on Jan which is 6 months a head\n",
    "\n",
    "So, accumulating data a head of time for machine learning/analysis is pretty complex and confusing.\n",
    "\n",
    "I have deviced the following way to over come this complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "## 1. Download Source data - Manual Process\n",
    "- Download data from decided known source and save as such as json file in the '**dataName**/data/raw/**frequency**' folder\n",
    "- every time you save a new fragment of data, make sure that you are saving the file with names which are always in ascending order alphabetically. For example, save new files with the name confining to the series say '01.json,02.json,03.json ... and so on..' or like 'aa.json, ab.json, aca.json,acab.json,ad.json and so on...' \n",
    "- Please try to follow an ascending alphabetic file pattern for every for every new file name to AVOID issues.\n",
    "- Should still work with casual file names as well\n",
    "- Download and save data this way as frequent as possible for as many products as required\n",
    "\n",
    "## 2. Configure Input Cell - Manual Process\n",
    "- Provide the following inputs namely\n",
    "    - dataName\n",
    "    - dataFrequency\n",
    "    - stockExpiresOnDate\n",
    "    \n",
    "For crudeOil a typical example would be\n",
    "\n",
    "> dataName = 'crudeOil_India' <br>\n",
    "  dataFrequency = '5m'<br>\n",
    "  stockExpiresOnDate = 18\n",
    "\n",
    "Do not modify any other code present in the input cell and change only the other input parameter named 'noteBookRelativeDepthFromRoot' only if necessary\n",
    "\n",
    "This will take care of the initializing the Jupyter Notebook environment to perform the desired data manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create  !!dataName!!_HistoricalData.csv - Manual ( Semi Automatic) \n",
    "> (eg crudeOil_India_HistoricalData.csv)<br>\n",
    "(One time only) <br>\n",
    "**NOTE**: You may **NOT have to repeat this step** if it has been done in the past\n",
    "\n",
    "- a file with frozen historical market data for each commodity has to be saved in the following folder location:\n",
    "    - '**!!dataName!!**/data/raw/**!!dataFrequency!!**/frozenHistoricalData' \n",
    "- gather as much data as possible for the current running month's stock\n",
    "- define the data as \"**dataName**H\n",
    "\", for example \"crudeOilHistoricalData.csv\". Freeze this data.\n",
    "- data can only be added to this file but never any entry should be modified\n",
    "\n",
    "## 4. Create !!dataName!!_!!month!!~.csv - Manual ( Semi Automatic)\n",
    "> (eg crudeOil_Jun.csv) \n",
    "\n",
    "- gather current month data till 18th of the next calendar month as much as possible\n",
    "- remove all entries in the current  month data for which historical data is already present in say 'crudeOilHistoricalData.csv)\n",
    "- add the remaining data in the current month to the historical data and call it as say 'crudeOil_mar.csv'\n",
    "\n",
    "## 5. Update and Archive Expiried Commodity Stock Data - Manual ( Semi Automatic)\n",
    "- as soon as stock for the current month expires, update the historical data with the existing data and archive the current month based file\n",
    "\n",
    "## Update crudeOilHistoricalData.csv every cycle and repeat previous step\n",
    "\n",
    "- When a new month's stock starts every 19th of the month archive the 'crudeOilHistoricalData.csv' file\n",
    "- Rename 'crudeOil_month.csv' into 'crudeOilHistoricalData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path >>> /Users/493055/Desktop/dev/erai-v0.3/src <<< appended to sys path - Mandatory for the pythons files in src folder to be recognized\n"
     ]
    }
   ],
   "source": [
    "# DO NOT MODIFY THE FOLLOWING UNLESS THE NOTEBOOK'S LOCATION HAS CHANGED AND IS NECESSARY\n",
    "noteBookRelativeDepthFromRoot = '../../'\n",
    "\n",
    "import os\n",
    "import sys  \n",
    "module_path = os.path.abspath(noteBookRelativeDepthFromRoot + os.path.join('.'))\n",
    "\n",
    "sys.path.append(module_path)\n",
    "\n",
    "print(\"module_path >>> \" + module_path + \" <<< appended to sys path - Mandatory for the pythons files in src folder to be recognized\")\n",
    "\n",
    "\n",
    "from dataPreprocessing import *\n",
    "from dataPreprocessing.preProcessData import preProcessCommodityData\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crude5mDataParamSet = ('crudeOil_India','5m')\n",
    "crude1hDataParamSet = ('crudeOil_India','1h')\n",
    "crude1dDataParamSet = ('crudeOil_India','1d')\n",
    "\n",
    "naturalGas5mDataParamSet = ('naturalGas','5m')\n",
    "naturalGas1hDataParamSet = ('naturalGas','1h')\n",
    "naturalGas1dDataParamSet = ('naturalGas','1d')\n",
    "\n",
    "adani5mDataParamSet = ('adani','5m')\n",
    "adani1hDataParamSet = ('adani','1h')\n",
    "adani1dDataParamSet = ('adani','1d')\n",
    "\n",
    "alumini5mDataParamSet = ('alumini','5m')\n",
    "alumini1hDataParamSet = ('alumini','1h')\n",
    "alumini1dDataParamSet = ('alumini','1d')\n",
    "\n",
    "aluminium5mDataParamSet = ('aluminium','5m')\n",
    "aluminium1hDataParamSet = ('aluminium','1h')\n",
    "aluminium1dDataParamSet = ('aluminium','1d')\n",
    "\n",
    "cardamon5mDataParamSet = ('cardamon','5m')\n",
    "cardamon1hDataParamSet = ('cardamon','1h')\n",
    "cardamon1dDataParamSet = ('cardamon','1d')\n",
    "\n",
    "copper5mDataParamSet = ('copper','5m')\n",
    "copper1hDataParamSet = ('copper','1h')\n",
    "copper1dDataParamSet = ('copper','1d')\n",
    "\n",
    "cotton5mDataParamSet = ('cotton','5m')\n",
    "cotton1hDataParamSet = ('cotton','1h')\n",
    "cotton1dDataParamSet = ('cotton','1d')\n",
    "\n",
    "cpo5mDataParamSet = ('cpo','5m')\n",
    "cpo1hDataParamSet = ('cpo','1h')\n",
    "cpo1dDataParamSet = ('cpo','1d')\n",
    "\n",
    "gold5mDataParamSet = ('gold','5m')\n",
    "gold1hDataParamSet = ('gold','1h')\n",
    "gold1dDataParamSet = ('gold','1d')\n",
    "\n",
    "goldguinea5mDataParamSet = ('goldguinea','5m')\n",
    "goldguinea1hDataParamSet = ('goldguinea','1h')\n",
    "goldguinea1dDataParamSet = ('goldguinea','1d')\n",
    "\n",
    "goldm5mDataParamSet = ('goldm','5m')\n",
    "goldm1hDataParamSet = ('goldm','1h')\n",
    "goldm1dDataParamSet = ('goldm','1d')\n",
    "\n",
    "goldpetal5mDataParamSet = ('goldpetal','5m')\n",
    "goldpetal1hDataParamSet = ('goldpetal','1h')\n",
    "goldpetal1dDataParamSet = ('goldpetal','1d')\n",
    "\n",
    "kapas5mDataParamSet = ('kapas','5m')\n",
    "kapas1hDataParamSet = ('kapas','1h')\n",
    "kapas1dDataParamSet = ('kapas','1d')\n",
    "\n",
    "lead5mDataParamSet = ('lead','5m')\n",
    "lead1hDataParamSet = ('lead','1h')\n",
    "lead1dDataParamSet = ('lead','1d')\n",
    "\n",
    "leadmini5mDataParamSet = ('leadmini','5m')\n",
    "leadmini1hDataParamSet = ('leadmini','1h')\n",
    "leadmini1dDataParamSet = ('leadmini','1d')\n",
    "\n",
    "menthaoil5mDataParamSet = ('menthaoil','5m')\n",
    "menthaoil1hDataParamSet = ('menthaoil','1h')\n",
    "menthaoil1dDataParamSet = ('menthaoil','1d')\n",
    "\n",
    "nickel5mDataParamSet = ('nickel','5m')\n",
    "nickel1hDataParamSet = ('nickel','1h')\n",
    "nickel1dDataParamSet = ('nickel','1d')\n",
    "\n",
    "silver5mDataParamSet = ('silver','5m')\n",
    "silver1hDataParamSet = ('silver','1h')\n",
    "silver1dDataParamSet = ('silver','1d')\n",
    "\n",
    "silverm5mDataParamSet = ('silverm','5m')\n",
    "silverm1hDataParamSet = ('silverm','1h')\n",
    "silverm1dDataParamSet = ('silverm','1d')\n",
    "\n",
    "silvermic5mDataParamSet = ('silvermic','5m')\n",
    "silvermic1hDataParamSet = ('silvermic','1h')\n",
    "silvermic1dDataParamSet = ('silvermic','1d')\n",
    "\n",
    "zinc5mDataParamSet = ('zinc','5m')\n",
    "zinc1hDataParamSet = ('zinc','1h')\n",
    "zinc1dDataParamSet = ('zinc','1d')\n",
    "\n",
    "zincmini5mDataParamSet = ('zincmini','5m')\n",
    "zincmini1hDataParamSet = ('zincmini','1h')\n",
    "zincmini1dDataParamSet = ('zincmini','1d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Preprocessing raw commodity data\n",
      "checking for data files in >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOil_India/raw/5m\n",
      "looping through all the files to create input data\n",
      "No raw data files found to process\n",
      "done processing 5 minute frequency data\n"
     ]
    }
   ],
   "source": [
    "preProcessedInfo_5m = preProcessCommodityData(dataName=crude5mDataParamSet[0],\n",
    "                                              dataFrequency=crude5mDataParamSet[1])\n",
    "print('done processing 5 minute frequency data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Preprocessing raw commodity data\n",
      "checking for data files in >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOil_India/raw/1h\n",
      "looping through all the files to create input data\n",
      "No raw data files found to process\n",
      "done processing 1h frequency data\n"
     ]
    }
   ],
   "source": [
    "preProcessedInfo_1h = preProcessCommodityData(dataName=crude1hDataParamSet[0],\n",
    "                                              dataFrequency=crude1hDataParamSet[1])\n",
    "print('done processing 1h frequency data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Preprocessing raw commodity data\n",
      "checking for data files in >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOil_India/raw/1d\n",
      "looping through all the files to create input data\n",
      "No raw data files found to process\n",
      "done processing 1d frequency data\n"
     ]
    }
   ],
   "source": [
    "preProcessedInfo_1d = preProcessCommodityData(dataName=crude1dDataParamSet[0],\n",
    "                                              dataFrequency=crude1dDataParamSet[1])\n",
    "print('done processing 1d frequency data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Preprocessing raw commodity data\n",
      "checking for data files in >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m\n",
      "looping through all the files to create input data\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/01.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/06.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/07.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/04.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/05.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/02.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/03.json ...\n",
      "File read - SUCCESS\n",
      " checking if folder existis >>>/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/frozenHistoricalData\n",
      "Debug >>> start >>> isFileExists method\n",
      "Debug >>> isFileExists >>> projectRootFolderPath = /Users/493055/Desktop/dev/erai-v0.3\n",
      "Debug >>> isFileExists >>> valueError\n",
      "DEBUG >>> isFileExists >>> rootFolderPathIndex = -1\n",
      "Debug >>> check if file path exists >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/frozenHistoricalData/naturalGas_HistoricalData.csv\n",
      "Debug >>> end >>> isFileExists method\n",
      "historical record exists\n",
      "cutoffDateFromPenultimateValueInHistoricalData = 2020-03-03T19:00:00+0530\n",
      "Debug >>> newValuesDf droped date column\n",
      "historical record data updated\n",
      " debug >>> archiveFileInRawDataFolder >>> into method\n",
      " checking if folder existis >>>/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive\n",
      " checking if folder existis >>>/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive/archive_1583817758.557622\n",
      "/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive/archive_1583817758.557622 >>> Folder created\n",
      " debug >>> archiveFileInRawDataFolder >>> about to loop through filelist\n",
      " debug >>> archiveFileInRawDataFolder >>> attempting to copy file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/01.json\n",
      "to location >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive/archive_1583817758.557622/01.json\n",
      "File deleted >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/01.json\n",
      " debug >>> archiveFileInRawDataFolder >>> attempting to copy file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/06.json\n",
      "to location >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive/archive_1583817758.557622/06.json\n",
      "File deleted >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/06.json\n",
      " debug >>> archiveFileInRawDataFolder >>> attempting to copy file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/07.json\n",
      "to location >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive/archive_1583817758.557622/07.json\n",
      "File deleted >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/07.json\n",
      " debug >>> archiveFileInRawDataFolder >>> attempting to copy file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/04.json\n",
      "to location >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive/archive_1583817758.557622/04.json\n",
      "File deleted >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/04.json\n",
      " debug >>> archiveFileInRawDataFolder >>> attempting to copy file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/05.json\n",
      "to location >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive/archive_1583817758.557622/05.json\n",
      "File deleted >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/05.json\n",
      " debug >>> archiveFileInRawDataFolder >>> attempting to copy file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/02.json\n",
      "to location >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive/archive_1583817758.557622/02.json\n",
      "File deleted >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/02.json\n",
      " debug >>> archiveFileInRawDataFolder >>> attempting to copy file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/03.json\n",
      "to location >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/archive/archive_1583817758.557622/03.json\n",
      "File deleted >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/5m/03.json\n",
      " debug >>> archiveFileInRawDataFolder >>> completed method\n",
      " debug >>> archiveFileInRawDataFolder >>> returning value >>> True\n",
      "debug >>> all files archived successfully\n",
      "done processing 5m frequency data\n"
     ]
    }
   ],
   "source": [
    "preProcessedInfo_naturalGas_5m = preProcessCommodityData(dataName=naturalGas5mDataParamSet[0],\n",
    "                                              dataFrequency=naturalGas5mDataParamSet[1])\n",
    "print('done processing 5m frequency data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Preprocessing raw commodity data\n",
      "checking for data files in >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h\n",
      "looping through all the files to create input data\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h/01.json ...\n",
      "File read - SUCCESS\n",
      " checking if folder existis >>>/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h/frozenHistoricalData\n",
      "Debug >>> start >>> isFileExists method\n",
      "Debug >>> isFileExists >>> projectRootFolderPath = /Users/493055/Desktop/dev/erai-v0.3\n",
      "Debug >>> isFileExists >>> valueError\n",
      "DEBUG >>> isFileExists >>> rootFolderPathIndex = -1\n",
      "Debug >>> check if file path exists >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h/frozenHistoricalData/naturalGas_HistoricalData.csv\n",
      "Debug >>> end >>> isFileExists method\n",
      "historical record exists\n",
      "cutoffDateFromPenultimateValueInHistoricalData = 2020-03-03T18:00:00+0530\n",
      "Debug >>> newValuesDf droped date column\n",
      "historical record data updated\n",
      " debug >>> archiveFileInRawDataFolder >>> into method\n",
      " checking if folder existis >>>/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h/archive\n",
      " checking if folder existis >>>/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h/archive/archive_1583817760.7917519\n",
      "/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h/archive/archive_1583817760.7917519 >>> Folder created\n",
      " debug >>> archiveFileInRawDataFolder >>> about to loop through filelist\n",
      " debug >>> archiveFileInRawDataFolder >>> attempting to copy file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h/01.json\n",
      "to location >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h/archive/archive_1583817760.7917519/01.json\n",
      "File deleted >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1h/01.json\n",
      " debug >>> archiveFileInRawDataFolder >>> completed method\n",
      " debug >>> archiveFileInRawDataFolder >>> returning value >>> True\n",
      "debug >>> all files archived successfully\n",
      "done processing 1h frequency data\n"
     ]
    }
   ],
   "source": [
    "preProcessedInfo_naturalGas_1h = preProcessCommodityData(dataName=naturalGas1hDataParamSet[0],\n",
    "                                              dataFrequency=naturalGas1hDataParamSet[1])\n",
    "print('done processing 1h frequency data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Preprocessing raw commodity data\n",
      "checking for data files in >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d\n",
      "looping through all the files to create input data\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d/01.json ...\n",
      "File read - SUCCESS\n",
      " checking if folder existis >>>/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d/frozenHistoricalData\n",
      "Debug >>> start >>> isFileExists method\n",
      "Debug >>> isFileExists >>> projectRootFolderPath = /Users/493055/Desktop/dev/erai-v0.3\n",
      "Debug >>> isFileExists >>> valueError\n",
      "DEBUG >>> isFileExists >>> rootFolderPathIndex = -1\n",
      "Debug >>> check if file path exists >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d/frozenHistoricalData/naturalGas_HistoricalData.csv\n",
      "Debug >>> end >>> isFileExists method\n",
      "historical record exists\n",
      "cutoffDateFromPenultimateValueInHistoricalData = 2020-03-02T00:00:00+0530\n",
      "Debug >>> newValuesDf droped date column\n",
      "historical record data updated\n",
      " debug >>> archiveFileInRawDataFolder >>> into method\n",
      " checking if folder existis >>>/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d/archive\n",
      " checking if folder existis >>>/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d/archive/archive_1583817762.981419\n",
      "/Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d/archive/archive_1583817762.981419 >>> Folder created\n",
      " debug >>> archiveFileInRawDataFolder >>> about to loop through filelist\n",
      " debug >>> archiveFileInRawDataFolder >>> attempting to copy file >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d/01.json\n",
      "to location >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d/archive/archive_1583817762.981419/01.json\n",
      "File deleted >>> /Users/493055/Desktop/dev/erai-v0.3/data/naturalGas/raw/1d/01.json\n",
      " debug >>> archiveFileInRawDataFolder >>> completed method\n",
      " debug >>> archiveFileInRawDataFolder >>> returning value >>> True\n",
      "debug >>> all files archived successfully\n",
      "done processing 1d frequency data\n"
     ]
    }
   ],
   "source": [
    "preProcessedInfo_naturalGas_1d = preProcessCommodityData(dataName=naturalGas1dDataParamSet[0],\n",
    "                                              dataFrequency=naturalGas1dDataParamSet[1])\n",
    "print('done processing 1d frequency data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
