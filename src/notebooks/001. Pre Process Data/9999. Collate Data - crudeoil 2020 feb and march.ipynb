{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path >>> /Users/493055/Desktop/dev/erai-v0.3/src <<< appended to sys path - Mandatory for the pythons files in src folder to be recognized\n"
     ]
    }
   ],
   "source": [
    "dataName = 'crudeOilFeb'\n",
    "dataFrequency='5m'\n",
    "\n",
    "import os\n",
    "import sys  \n",
    "module_path = os.path.abspath('../../'+os.path.join('.'))\n",
    "\n",
    "sys.path.append(module_path)\n",
    "\n",
    "print(\"module_path >>> \" + module_path + \" <<< appended to sys path - Mandatory for the pythons files in src folder to be recognized\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from dataPreprocessing import *\n",
    "\n",
    "# from dataPreprocessing.preProcessData import collateData\n",
    "\n",
    "# df = collateData(dataName,dataFrequency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data pre-processing >> imported dependencies\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from utils.errorHandler import handleError\n",
    "from utils.common import getProjectRootFolderPath\n",
    "\n",
    "from utils.fileFolderManipulations import getParentFolder\n",
    "from utils.fileFolderManipulations import createFolder\n",
    "\n",
    "from config.config import getAppConfigData\n",
    "from config.config import setAppConfigData\n",
    "\n",
    "from fastai.tabular import add_datepart\n",
    "\n",
    "from dataPreparation.simpleFeatures import getFollowingHolidaysDaysStamp\n",
    "from dataPreparation.simpleFeatures import getPriorHoliDaysStamps\n",
    "\n",
    "print(' data pre-processing >> imported dependencies')\n",
    "\n",
    "relativeDataFolderPath = 'data/'+dataName+'/raw/' + dataFrequency\n",
    "\n",
    "# Variable to hold the original source folder path which is calculated from the input relative path of the source folder (relativeDataFolderPath)\n",
    "# using various python commands like os.path.abspath and os.path.join\n",
    "projectRootFolderPath = None\n",
    "\n",
    "# Variable to hold a dataframe created with the data from input data files in the relativeDataFolderPath provided\n",
    "inputRawDataDF = None\n",
    "\n",
    "# Variable to hold the original source folder path which is calculated from the input relative path of the source folder (relativeDataFolderPath)\n",
    "# using various python commands like os.path.abspath and os.path.join\n",
    "dataFolderPath = None\n",
    "\n",
    "# Variable to hold query like value of python to query all json file names in the source folder (dataFolderPath).\n",
    "# Will be used in the glob function to execute the query\n",
    "json_pattern = None\n",
    "\n",
    "# Variable to contain the list of all input json file names in the source folder (dataFolderPath)\n",
    "file_list = None\n",
    "\n",
    "# return values of this method\n",
    "# -------------------------------------------------------------------------------\n",
    "# Current methods return value initialized to false. Will be maked as true\n",
    "# after every single line in the method has been executed with out errors\n",
    "returnValue = False\n",
    "# complete filepath of the csv file with the processed raw data\n",
    "outputFilePath = None\n",
    "outputFolderName = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caluclate the deployment directory path of the current juypter node in the operating system\n",
    "projectRootFolderPath = getProjectRootFolderPath()\n",
    "\n",
    "# TO BE MODIFIED - NOT SURE WHY I USED THIS - WILL HAVE TO CHECK\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# creating pandas dataframe references for further modification\n",
    "inputRawDataDF = pd.DataFrame()\n",
    "\n",
    "# calculating the complete data folder path of the relative path provided as parameter\n",
    "dataFolderPath = projectRootFolderPath + '/'+relativeDataFolderPath\n",
    "\n",
    "# creating OS queryable object for python to work with to find json files in the dataFolderPath calcuated in the previous step\n",
    "json_pattern = os.path.join(dataFolderPath, '*.json')\n",
    "\n",
    "# store all the json file paths in the dataFolderPath for further processing\n",
    "file_list = glob.glob(json_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/01.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/06.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/07.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/04.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/08.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/09.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/05.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/02.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/03.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/01.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/02.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/03.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/04.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/05.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/06.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/07.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/08.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/09.json']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list.sort()\n",
    "file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/01.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/02.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/03.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/04.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/05.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/06.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/07.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/08.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeOilFeb/raw/5m/09.json ...\n",
      "File read - SUCCESS\n"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    print(\"reading input file >>> \" + file + \" ...\")\n",
    "    data=None\n",
    "    try:\n",
    "        # read json data from unformatted json file\n",
    "        data = pd.read_json(file, lines=True)\n",
    "\n",
    "        if isinstance(data, str):\n",
    "            data = data['data'][0]['candles']\n",
    "        elif isinstance(data,pd.DataFrame):\n",
    "            data = data['data'][0]['candles']\n",
    "        else:\n",
    "            data = data.values[0][0]['candles']\n",
    "\n",
    "    except ValueError:\n",
    "        # read data from formatted / json linted json file\n",
    "        data = pd.read_json(file)\n",
    "\n",
    "        data = data['data'][0]\n",
    "\n",
    "\n",
    "    inputRawDataDF = inputRawDataDF.append(data, ignore_index=True)\n",
    "    print(\"File read - SUCCESS\")\n",
    "\n",
    "#assign column names\n",
    "inputRawDataDF.columns = ['date-time', 'open',\n",
    "                          'high', 'low', 'close', 'quantity', 'dont-know']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdataDf  = inputRawDataDF \n",
    "rawdataDf.index = rawdataDf['date-time']\n",
    "rawdataDf = rawdataDf.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8859, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdataDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8262, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdataDf=rawdataDf.groupby(inputRawDataDF.index).last()\n",
    "rawdataDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdataDf.to_csv(projectRootFolderPath+'/01.crudeoil_feb_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " data pre-processing >> imported dependencies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/493055/Desktop/dev/erai-v0.3/data/crudeoil_india/raw/5m/01.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeoil_india/raw/5m/02.json',\n",
       " '/Users/493055/Desktop/dev/erai-v0.3/data/crudeoil_india/raw/5m/03.json']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataName = 'crudeoil_india'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from utils.errorHandler import handleError\n",
    "from utils.common import getProjectRootFolderPath\n",
    "\n",
    "from utils.fileFolderManipulations import getParentFolder\n",
    "from utils.fileFolderManipulations import createFolder\n",
    "\n",
    "from config.config import getAppConfigData\n",
    "from config.config import setAppConfigData\n",
    "\n",
    "from fastai.tabular import add_datepart\n",
    "\n",
    "from dataPreparation.simpleFeatures import getFollowingHolidaysDaysStamp\n",
    "from dataPreparation.simpleFeatures import getPriorHoliDaysStamps\n",
    "\n",
    "print(' data pre-processing >> imported dependencies')\n",
    "\n",
    "relativeDataFolderPath = 'data/'+dataName+'/raw/' + dataFrequency\n",
    "\n",
    "# Variable to hold the original source folder path which is calculated from the input relative path of the source folder (relativeDataFolderPath)\n",
    "# using various python commands like os.path.abspath and os.path.join\n",
    "projectRootFolderPath = None\n",
    "\n",
    "# Variable to hold a dataframe created with the data from input data files in the relativeDataFolderPath provided\n",
    "inputRawDataDF = None\n",
    "\n",
    "# Variable to hold the original source folder path which is calculated from the input relative path of the source folder (relativeDataFolderPath)\n",
    "# using various python commands like os.path.abspath and os.path.join\n",
    "dataFolderPath = None\n",
    "\n",
    "# Variable to hold query like value of python to query all json file names in the source folder (dataFolderPath).\n",
    "# Will be used in the glob function to execute the query\n",
    "json_pattern = None\n",
    "\n",
    "# Variable to contain the list of all input json file names in the source folder (dataFolderPath)\n",
    "file_list = None\n",
    "\n",
    "# return values of this method\n",
    "# -------------------------------------------------------------------------------\n",
    "# Current methods return value initialized to false. Will be maked as true\n",
    "# after every single line in the method has been executed with out errors\n",
    "returnValue = False\n",
    "# complete filepath of the csv file with the processed raw data\n",
    "outputFilePath = None\n",
    "outputFolderName = None\n",
    "\n",
    "# caluclate the deployment directory path of the current juypter node in the operating system\n",
    "projectRootFolderPath = getProjectRootFolderPath()\n",
    "\n",
    "# TO BE MODIFIED - NOT SURE WHY I USED THIS - WILL HAVE TO CHECK\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# creating pandas dataframe references for further modification\n",
    "inputRawDataDF = pd.DataFrame()\n",
    "\n",
    "# calculating the complete data folder path of the relative path provided as parameter\n",
    "dataFolderPath = projectRootFolderPath + '/'+relativeDataFolderPath\n",
    "\n",
    "# creating OS queryable object for python to work with to find json files in the dataFolderPath calcuated in the previous step\n",
    "json_pattern = os.path.join(dataFolderPath, '*.json')\n",
    "\n",
    "# store all the json file paths in the dataFolderPath for further processing\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeoil_india/raw/5m/01.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeoil_india/raw/5m/02.json ...\n",
      "File read - SUCCESS\n",
      "reading input file >>> /Users/493055/Desktop/dev/erai-v0.3/data/crudeoil_india/raw/5m/03.json ...\n",
      "File read - SUCCESS\n"
     ]
    }
   ],
   "source": [
    "file_list.sort()\n",
    "for file in file_list:\n",
    "    print(\"reading input file >>> \" + file + \" ...\")\n",
    "    data=None\n",
    "    try:\n",
    "        # read json data from unformatted json file\n",
    "        data = pd.read_json(file, lines=True)\n",
    "\n",
    "        if isinstance(data, str):\n",
    "            data = data['data'][0]['candles']\n",
    "        elif isinstance(data,pd.DataFrame):\n",
    "            data = data['data'][0]['candles']\n",
    "        else:\n",
    "            data = data.values[0][0]['candles']\n",
    "\n",
    "    except ValueError:\n",
    "        # read data from formatted / json linted json file\n",
    "        data = pd.read_json(file)\n",
    "\n",
    "        data = data['data'][0]\n",
    "\n",
    "\n",
    "    inputRawDataDF = inputRawDataDF.append(data, ignore_index=True)\n",
    "    print(\"File read - SUCCESS\")\n",
    "\n",
    "#assign column names\n",
    "inputRawDataDF.columns = ['date-time', 'open',\n",
    "                          'high', 'low', 'close', 'quantity', 'dont-know']\n",
    "\n",
    "rawdataDf  = inputRawDataDF \n",
    "rawdataDf.index = rawdataDf['date-time']\n",
    "rawdataDf = rawdataDf.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6963, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdataDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6963, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdataDf=rawdataDf.groupby(inputRawDataDF.index).last()\n",
    "rawdataDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdataDf.to_csv(projectRootFolderPath+'/01.crudeoil_mar_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
